{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d1ca58",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N°3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad20063",
   "metadata": {},
   "source": [
    "\n",
    "    img_align_celeba.zip: All the face images, cropped and aligned\n",
    "    list_eval_partition.csv: Recommended partitioning of images into training, validation, testing sets. Images 1-162770 are training, 162771-182637 are validation, 182638-202599 are testing\n",
    "    list_bbox_celeba.csv: Bounding box information for each image. \"x_1\" and \"y_1\" represent the upper left point coordinate of bounding box. \"width\" and \"height\" represent the width and height of bounding box\n",
    "    list_landmarks_align_celeba.csv: Image landmarks and their respective coordinates. There are 5 landmarks: left eye, right eye, nose, left mouth, right mouth\n",
    "    list_attr_celeba.csv: Attribute labels for each image. There are 40 attributes. \"1\" represents positive while \"-1\" represents negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagenes_DIR = Path('./dataset_TP3/img_align_celeba')\n",
    "IMG_PATH = Path('/home/matias/Documentos/archive/img_align_celeba/img_align_celeba')\n",
    "atributos_DIR = Path('/home/matias/Documentos/archive/list_attr_celeba.csv')\n",
    "set_DIR = Path('/home/matias/Documentos/archive/list_eval_partition.csv')\n",
    "\n",
    "da = pd.read_csv(atributos_DIR, usecols=['image_id','No_Beard'])\n",
    "dd = pd.read_csv(set_DIR)\n",
    "df=da.merge(dd, on=\"image_id\", how=\"left\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the columns values to categorical./\n",
    "df.loc[df['No_Beard'] == -1,'No_Beard'] = \"Barba\"\n",
    "df.loc[df['No_Beard'] == 1,'No_Beard'] = \"No_Barba\"\n",
    "\n",
    "train = df.loc[df['partition'] == 0]\n",
    "validation = df.loc[df['partition'] == 1]\n",
    "test= df.loc[df['partition'] == 2]\n",
    "\n",
    "train=train.drop(['partition'],axis=1)\n",
    "validation=validation.drop(['partition'],axis=1)\n",
    "test=test.drop(['partition'],axis=1)\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b27886",
   "metadata": {},
   "source": [
    "# Análisis exploratorio del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9e794",
   "metadata": {},
   "source": [
    "Aclarar que archivos hay en el dataset, cuales usamos y como juntamos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663ff6c",
   "metadata": {},
   "source": [
    "### Distribución de la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe958f",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count = df[\"No_Beard\"].value_counts()\n",
    "print(category_count)\n",
    "\n",
    "higher_category = list(category_count.index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"No_Beard\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e10dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos=np.array(df)\n",
    "atributos[148010][1] # uno menos \n",
    "\n",
    "#hacer labels con lo de los atributos.no_beard\n",
    "#hacer x_train(imagenes, tamaño, tamaño)\n",
    "#hacer y_train(atributos.no_beard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ffef1",
   "metadata": {},
   "source": [
    "### Por partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf850a",
   "metadata": {},
   "source": [
    "### Estructura y tipo de imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba/000002.jpg'  # Reemplaza con la ruta de tu imagen\n",
    "img = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689963c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ancho: {width} píxeles')\n",
    "print(f'Alto: {height} píxeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e862ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = np.array(img)\n",
    "depth = img_array.shape[2]\n",
    "print(f'Profundidad de la imagen: {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8312757",
   "metadata": {},
   "source": [
    "Según lo visto anteriormente concluimos que poe cuestiones de tiempo de entrenamiento vamos a aplicar los siguientes cambios a las imagenes al armar los conjuntos de entrenaminto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")\n",
    "\n",
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "    test, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = dataset.next()\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(6,6,i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(labels[i])\n",
    "        #print(images[17][26])\n",
    "        \n",
    "        #print(labels[i])\n",
    "        #print(i)\n",
    "        #clase=atributos[i][26]\n",
    "        #plt.title(class_name[clase])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72233828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf768313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f34f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7613e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb365c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3b7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc474c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b54e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a03ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ae334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b3e7c1c",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape= IMAGE_SIZE + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73049978",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model.trainable = False\n",
    "base_vgg_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23819",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential(\n",
    "    [\n",
    "    base_vgg_model,\n",
    "    Flatten(),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db44b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=4, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "\n",
    "history = vgg_model.fit(train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation_df)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train_df)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23d967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "pretrained_model = VGG16(include_top=False, input_shape= IMAGE_SIZE + (3,))\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "vgg16_model = Sequential(\n",
    "    [\n",
    "    pretrained_model,\n",
    "    #Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    #MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "\n",
    "vgg16_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38852ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_at_epochs = {}\n",
    "\n",
    "class OurCustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_weights_at_epochs[epoch] = self.model.get_weights()\n",
    "        \n",
    "history = vgg16_model.fit(\n",
    "    train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=[OurCustomCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "train, test = fashion_mnist.load_data()\n",
    "(x_train, y_train) = train \n",
    "(x_test, y_test) = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680812a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = fashion_mnist.load_data()\n",
    "(x_train, y_train) = train \n",
    "(x_test, y_test) = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56497199",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = validation_datagen.flow_from_dataframe(\n",
    "    train, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")\n",
    "\n",
    "data_array, labels_array = train_generator.next()\n",
    "    \n",
    "data_array = []\n",
    "labels_array = []\n",
    "\n",
    "for _ in range(BATCH_SIZE):\n",
    "    batch_data, batch_labels = train_generator.next()\n",
    "    data_array.append(batch_data)\n",
    "    labels_array.append(batch_labels)\n",
    "\n",
    "data_array = np.concatenate(data_array)\n",
    "labels_array = np.concatenate(labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96156bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec25868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar imágenes\n",
    "def mostrar_imagenes(entradas, salidas):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(10):\n",
    "        plt.subplot(6,6,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(entradas[i])\n",
    "        plt.xlabel(salidas[i])\n",
    "    plt.show()\n",
    "\n",
    "mostrar_imagenes(data_array, labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ad647",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125510c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
