{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d1ca58",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N°3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad20063",
   "metadata": {},
   "source": [
    "\n",
    "    img_align_celeba.zip: All the face images, cropped and aligned\n",
    "    list_eval_partition.csv: Recommended partitioning of images into training, validation, testing sets. Images 1-162770 are training, 162771-182637 are validation, 182638-202599 are testing\n",
    "    list_bbox_celeba.csv: Bounding box information for each image. \"x_1\" and \"y_1\" represent the upper left point coordinate of bounding box. \"width\" and \"height\" represent the width and height of bounding box\n",
    "    list_landmarks_align_celeba.csv: Image landmarks and their respective coordinates. There are 5 landmarks: left eye, right eye, nose, left mouth, right mouth\n",
    "    list_attr_celeba.csv: Attribute labels for each image. There are 40 attributes. \"1\" represents positive while \"-1\" represents negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagenes_DIR = Path('./dataset_TP3/img_align_celeba')\n",
    "IMG_PATH = Path('/home/matias/Documentos/archive/img_align_celeba/img_align_celeba')\n",
    "atributos_DIR = Path('/home/matias/Documentos/archive/list_attr_celeba.csv')\n",
    "set_DIR = Path('/home/matias/Documentos/archive/list_eval_partition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(atributos_DIR, usecols=['image_id','No_Beard'])\n",
    "\n",
    "# Reset the columns values to categorical./\n",
    "df.loc[df['No_Beard'] == -1,'No_Beard'] = \"Barba\"\n",
    "df.loc[df['No_Beard'] == 1,'No_Beard'] = \"No_Barba\"\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35983f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dfp = pd.read_csv(set_DIR)\n",
    "#dfp.shape(20)\n",
    "particion=np.array(dfp)\n",
    "atributos=np.array(df)\n",
    "x=len(df)\n",
    "\n",
    "def dividirDataset(atributos,particion):\n",
    "    iv=0\n",
    "    it=0\n",
    "    ite=0\n",
    "    for i in range(202599):\n",
    "        if (particion[i][1]==0):\n",
    "                train_df[it]=atributos[i][1]\n",
    "                it=it+1\n",
    "            else:\n",
    "                if (particion[i][1]==1):\n",
    "                    validation_df[iv]=atributos[i][1]\n",
    "                    iv=iv+1\n",
    "                else:\n",
    "                    test_df[ite]=atributos[i][1]\n",
    "                    ite=ite+1\n",
    "                    \n",
    "#dividirDataset(atributos,particion)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bdbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count = df[\"No_Beard\"].value_counts()\n",
    "print(category_count)\n",
    "\n",
    "higher_category = list(category_count.index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"No_Beard\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e10dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos=np.array(df)\n",
    "atributos[148010][1] # uno menos \n",
    "\n",
    "#hacer labels con lo de los atributos.no_beard\n",
    "#hacer x_train(imagenes, tamaño, tamaño)\n",
    "#hacer y_train(atributos.no_beard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d6ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216bc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3a08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b835c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971f25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689963c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a131c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_df = image_datagen.flow_from_directory(Imagenes_DIR)\n",
    "#completa=completa.merge(train, on=name, how=\"left\")\n",
    "#validation = images_reader.flow_from_directory(VALIDATION_DIR, **READ_PARAMS)\n",
    "\n",
    "train_df, test_df = train_test_split(df, train_size=0.80)\n",
    "test_df, validation_df = train_test_split(test_df, test_size=0.9)\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "print(len(validation_df))\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (218, 178)\n",
    "BATCH_SIZE = 15\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c019a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    images, labels = dataset.next()\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(6,6,i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(labels[i])\n",
    "        #print(images[17][26])\n",
    "        \n",
    "        #print(labels[i])\n",
    "        #print(i)\n",
    "        #clase=atributos[i][26]\n",
    "        #plt.title(class_name[clase])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72233828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf768313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f34f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7613e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb365c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3b7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc474c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b54e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a03ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ae334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c5a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape= IMAGE_SIZE + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73049978",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model.trainable = False\n",
    "base_vgg_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23819",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential(\n",
    "    [\n",
    "    base_vgg_model,\n",
    "    Flatten(),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db44b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=4, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "\n",
    "history = vgg_model.fit(train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation_df)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train_df)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23d967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = VGG16(include_top=False, input_shape= IMAGE_SIZE + (3,))\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "vgg16_model = Sequential(\n",
    "    [\n",
    "    pretrained_model,\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "]\n",
    ")\n",
    "\n",
    "vgg16_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38852ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_at_epochs = {}\n",
    "\n",
    "class OurCustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_weights_at_epochs[epoch] = self.model.get_weights()\n",
    "        \n",
    "history = vgg16_model.fit(\n",
    "    train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation_df)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train_df)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=[OurCustomCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
