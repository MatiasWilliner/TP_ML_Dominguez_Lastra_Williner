{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d1ca58",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N.° 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160f322",
   "metadata": {},
   "source": [
    "## Imports y configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b27886",
   "metadata": {},
   "source": [
    "# Análisis exploratorio sobre el conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54e198",
   "metadata": {},
   "source": [
    "Para que esto funcione, se debe bajar y descomprimir el archivo del siguiente [enlace](https://www.kaggle.com/jessicali9530/celeba-dataset). El mismo contiene:\n",
    "* **img_align_celeba**: imágenes de rostros, recortadas y alineadas.\n",
    "* **list_eval_partition.csv**: partición recomendada para las imagenes. Relaciona cada imagen con el atributo *partition*:\n",
    "    * \"0\" si pertenece al conjunto de entrenamiento.\n",
    "    * \"1\" si pertenece al conjunto de validación.\n",
    "    * \"2\" si pertenece al conjunto de prueba.\n",
    "* **list_bbox_celeba.csv**: información del cuadro delimitador para cada imagen.\n",
    "* **list_landmarks_align_celeba.csv**: puntos de referencia (ojo izquierdo, ojo derecho, nariz, boca izquierda, boca derecha) y sus respectivas coordenadas.\n",
    "* **list_attr_celeba.csv**: etiquetas (40 en total) de atributos para cada imagen. \"1\" representa positivo mientras que \"-1\" representa negativo.\n",
    "\n",
    "En nuestro caso, utilizaremos las imágenes, *list_eval_partition.csv* y *list_attr_celeba.csv* para desarrollar un modelo que sea capaz de detectar si una persona tiene o no barba a partir de una foto. Entonces, nuestro target será el atributo *No_Beard*, que determina si una persona en una imagen no tiene barba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar por la ruta donde se encuentran los archivos\n",
    "# current_path = '/home/matias/Documentos/archive/'\n",
    "current_path = '/home/yair/Files/archive/'\n",
    "\n",
    "imgs_path = Path(current_path, 'img_align_celeba/img_align_celeba')\n",
    "attr_path = Path(current_path, 'list_attr_celeba.csv')\n",
    "partitions_path = Path(current_path, 'list_eval_partition.csv')\n",
    "\n",
    "# Importamos y unimos los datasets de atributos y particiones\n",
    "df_attr = pd.read_csv(attr_path, usecols=['image_id','No_Beard'])\n",
    "df_partitions = pd.read_csv(partitions_path)\n",
    "df = df_attr.merge(df_partitions, on=\"image_id\", how=\"left\")\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343ac6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restablecemos los valores de la columna No_Beard\n",
    "df.loc[df['No_Beard'] == -1,'No_Beard'] = \"Barba\"\n",
    "df.loc[df['No_Beard'] == 1,'No_Beard'] = \"No_Barba\"\n",
    "\n",
    "# Dividimos el dataframe en función de la columna partition\n",
    "train = df.loc[df['partition'] == 0]\n",
    "validation = df.loc[df['partition'] == 1]\n",
    "test = df.loc[df['partition'] == 2]\n",
    "\n",
    "# Eliminamos la columna partition de los 3 conjuntos\n",
    "train = train.drop(['partition'],axis=1)\n",
    "validation = validation.drop(['partition'],axis=1)\n",
    "test = test.drop(['partition'],axis=1)\n",
    "\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26342a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad total de imágenes:\", len(df.image_id))\n",
    "print(\"Cantidad de imágenes en train:\", len(train.image_id))\n",
    "print(\"Cantidad de imágenes en validation:\", len(validation.image_id))\n",
    "print(\"Cantidad de imágenes en test:\", len(test.image_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809480b5",
   "metadata": {},
   "source": [
    "## Volumetría de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6648fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = Path(str(imgs_path) + '/000002.jpg') # Este solo es un ejemplo\n",
    "img = Image.open(img_path)\n",
    "\n",
    "width, height = img.size\n",
    "img_array = np.array(img)\n",
    "depth = img_array.shape[2]\n",
    "\n",
    "print(f'Alto de la imagen: {height} píxeles')\n",
    "print(f'Ancho de la imagen: {width} píxeles')\n",
    "print(f'Profundidad de la imagen (RGB): {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e663ff6c",
   "metadata": {},
   "source": [
    "## Distribución de la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count = df[\"No_Beard\"].value_counts()\n",
    "print(f'Cantidad total de imágenes de personas sin barba: {category_count.values[0]}')\n",
    "print(f'Cantidad total de imágenes de personas con barba: {category_count.values[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31decce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(16, 16))\n",
    "\n",
    "df.No_Beard.value_counts().plot.pie(autopct='%1.0f%%', label='', ax=axs[0])\n",
    "axs[0].set_title('Dataset completo')\n",
    "\n",
    "train.No_Beard.value_counts().plot.pie(autopct='%1.0f%%', label='', ax=axs[1])\n",
    "axs[1].set_title('Train')\n",
    "\n",
    "validation.No_Beard.value_counts().plot.pie(autopct='%1.0f%%', label='', ax=axs[2])\n",
    "axs[2].set_title('Validation')\n",
    "\n",
    "test.No_Beard.value_counts().plot.pie(autopct='%1.0f%%', label='', ax=axs[3])\n",
    "axs[3].set_title('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4d766",
   "metadata": {},
   "source": [
    "Podemos concluir entonces que la métrica F1 es la que mejor se ajusta al problema ya que se tiene un conjunto de datos que se encuentra desbalanceado. Esto nos permite ponderar el rendimiento del modelo con respecto a los falsos positivos y falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe958f",
   "metadata": {},
   "source": [
    "## Estructura y tipo de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19770383",
   "metadata": {},
   "source": [
    "Por cuestiones de tiempo de entrenamiento, vamos a aplicar cambios a las imágenes al armar los conjuntos de entrenamiento. Se va a reducir la dimensionalidad (alto y ancho), pasando de 218 x 178 píxeles a 64 x 64 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescalaremos los valores de las imágenes\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "# Para crear datasets de imágenes para Keras\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 100\n",
    "parameters = dict(\n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=(IMAGE_SIZE),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# Generar datasets\n",
    "train_generator = datagen.flow_from_dataframe(train, str(imgs_path) + \"/\",**parameters)\n",
    "validation_generator = datagen.flow_from_dataframe(validation,str(imgs_path) + \"/\",**parameters)\n",
    "test_generator = datagen.flow_from_dataframe(test, str(imgs_path) + \"/\",**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener un bloque (imagenes y etiquetas)\n",
    "train_imgs, train_labels = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de una imagen\n",
    "train_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar imagenes de ejemplo\n",
    "def draw_images(dataset):\n",
    "    cant_imgs = 15\n",
    "    row_plt = 3\n",
    "    col_plt = 5\n",
    "    images, labels = dataset.next()\n",
    "    for i in range(cant_imgs):\n",
    "        ax = plt.subplot(row_plt, col_plt, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(labels[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16950cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_images(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38703e",
   "metadata": {},
   "source": [
    "En los ejemplos anteriores podemos visualizar imagenes de tipo:\n",
    "* [0. 1.] indica que la persona no tiene barba.\n",
    "* [1. 0.] indica que la persona tiene barba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06068a41",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e7c1c",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape= IMAGE_SIZE + (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73049978",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vgg_model.trainable = False\n",
    "base_vgg_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23819",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential(\n",
    "    [\n",
    "    base_vgg_model,\n",
    "    Flatten(),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db44b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=4, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.001)\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "\n",
    "history = vgg_model.fit(train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation_df)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train_df)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=callbacks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23d967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "pretrained_model = VGG16(include_top=False, input_shape= IMAGE_SIZE + (3,))\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "vgg16_model = Sequential(\n",
    "    [\n",
    "    pretrained_model,\n",
    "    #Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    #MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "]\n",
    ")\n",
    "\n",
    "vgg16_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38852ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_at_epochs = {}\n",
    "\n",
    "class OurCustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_weights_at_epochs[epoch] = self.model.get_weights()\n",
    "        \n",
    "history = vgg16_model.fit(\n",
    "    train_generator, validation_data = validation_generator\n",
    "                        , validation_steps=len(validation)//BATCH_SIZE\n",
    "                        ,steps_per_epoch=len(train)//BATCH_SIZE,\n",
    "                        epochs=10, verbose = 1, callbacks=[OurCustomCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "train, test = fashion_mnist.load_data()\n",
    "(x_train, y_train) = train \n",
    "(x_test, y_test) = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680812a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = fashion_mnist.load_data()\n",
    "(x_train, y_train) = train \n",
    "(x_test, y_test) = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56497199",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = validation_datagen.flow_from_dataframe(\n",
    "    train, \n",
    "    '/home/matias/Documentos/archive/img_align_celeba/img_align_celeba'+'/', \n",
    "    x_col='image_id',\n",
    "    y_col='No_Beard',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    #validate_filenames=False\n",
    ")\n",
    "\n",
    "data_array, labels_array = train_generator.next()\n",
    "    \n",
    "data_array = []\n",
    "labels_array = []\n",
    "\n",
    "for _ in range(BATCH_SIZE):\n",
    "    batch_data, batch_labels = train_generator.next()\n",
    "    data_array.append(batch_data)\n",
    "    labels_array.append(batch_labels)\n",
    "\n",
    "data_array = np.concatenate(data_array)\n",
    "labels_array = np.concatenate(labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96156bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec25868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar imágenes\n",
    "def mostrar_imagenes(entradas, salidas):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(10):\n",
    "        plt.subplot(6,6,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(entradas[i])\n",
    "        plt.xlabel(salidas[i])\n",
    "    plt.show()\n",
    "\n",
    "mostrar_imagenes(data_array, labels_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ad647",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125510c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
