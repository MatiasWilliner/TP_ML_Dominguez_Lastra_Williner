{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d91ed06",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Entrenamiento y evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85887360",
   "metadata": {},
   "source": [
    "El caso de uso que se busca cubrir es el detectar si una jugada termina en home run o no cuando la bola ya fue bateada. Solo se va a poder usar dicho modelo para predecir el resultado de una jugada si se tienen los datos del lanzamiento y el bateo. Su principal uso está relacionado con el análisis de los factores que afectan a que una jugada sea home run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda09d4d",
   "metadata": {},
   "source": [
    "# Configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las dependencias necesarias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings, time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "warnings.filterwarnings('ignore')\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arreglamos el dataset según lo establecido en el TP1\n",
    "\n",
    "# Importamos train.csv y park_dimensions.csv, los unimos utilizando la variable \"park\"\n",
    "entrenamiento = pd.read_csv('./train.csv')\n",
    "estadio = pd.read_csv('./park_dimensions.csv')\n",
    "completa=entrenamiento.merge(estadio, on=\"park\", how=\"left\")\n",
    "\n",
    "# Desechamos las variables no utilizadas\n",
    "completa = completa.drop(['park','bip_id','batter_id','pitcher_id'],axis=1)\n",
    "\n",
    "# Asignamos nuevos nombres a las columnas\n",
    "renamed_columns = {'NAME': 'name', 'Cover': 'cover', 'LF_Dim': 'lf_dim', 'CF_Dim':'cf_dim',\n",
    "                   'RF_Dim': 'rf_dim', 'LF_W': 'lf_w', 'CF_W': 'cf_w', 'RF_W': 'rf_w'\n",
    "                  }\n",
    "completa.rename(columns=renamed_columns, inplace=True)\n",
    "\n",
    "# Convertir columna \"game_date\" de tipo object/string, a datetime\n",
    "completa['game_date'] = pd.to_datetime(completa['game_date'])\n",
    "\n",
    "# Eliminar datos filas con datos nulos en bb_type\n",
    "completa = completa[~completa.bb_type.isnull()]\n",
    "\n",
    "# Delimitación de conjuntos\n",
    "completa.isnull().sum()\n",
    "\n",
    "# Crear df a la que se le va aplicar feature engineering\n",
    "completa_fe = completa\n",
    "columnas_string=['game_date', 'batter_team','batter_name','pitcher_name','name']\n",
    "completa_fe = completa_fe.drop(columnas_string,axis=1)\n",
    "\n",
    "# Eliminar columnas cuyos valores sean cadenas\n",
    "columnas_string=['home_team','away_team', 'game_date', 'batter_team','batter_name','pitcher_name','name']\n",
    "completa = completa.drop(columnas_string,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a5b92",
   "metadata": {},
   "source": [
    "## División del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en train (60%), test (20%) y validation (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, not_train = train_test_split(completa, test_size=0.4, random_state=42)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=42)\n",
    "\n",
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el mapper. Recibe una lista de (columna/s, transformers)\n",
    "\n",
    "mapper = DataFrameMapper([ \n",
    "    (['is_batter_lefty'], None),\n",
    "    (['is_pitcher_lefty'], None),\n",
    "    (['bb_type'], [OneHotEncoder()]),\n",
    "    (['bearing'], [OneHotEncoder()]),\n",
    "    (['pitch_name'], [OneHotEncoder()]),\n",
    "    (['inning'], [StandardScaler()]),\n",
    "    (['outs_when_up'], None),\n",
    "    (['balls'], [StandardScaler()]),\n",
    "    (['strikes'], [StandardScaler()]),\n",
    "    (['plate_x'], [StandardScaler()]),\n",
    "    (['plate_z'], [StandardScaler()]),\n",
    "    (['pitch_mph'], [StandardScaler()]),\n",
    "    (['launch_speed'], [StandardScaler()]),\n",
    "    (['launch_angle'], [StandardScaler()]),\n",
    "    (['cover'], [OneHotEncoder()]),\n",
    "    (['lf_dim'], [StandardScaler()]),\n",
    "    (['cf_dim'], [StandardScaler()]),\n",
    "    (['rf_dim'], [StandardScaler()]),\n",
    "    (['lf_w'], [StandardScaler()]),\n",
    "    (['cf_w'], [StandardScaler()]),\n",
    "    (['rf_w'], [StandardScaler()]),\n",
    "])\n",
    "\n",
    "train_nor=train\n",
    "mapper.fit(train_nor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77439fd1",
   "metadata": {},
   "source": [
    "# Selección de métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e8e02",
   "metadata": {},
   "source": [
    "Decidimos utilizar Recall y Precision, debido a que los valores de la variable de salida no se encuentran balanceados.\n",
    "- Precision nos permite comprender el rendimiento de un clasificador con respecto a los falsos positivos (de los que clasificamos como Foo, qué porcentaje era realmente Foo).\n",
    "- Recall nos permite comprender el rendimiento de un clasificador con respecto a falsos negativos (de todos los Foo que había, qué porcentaje era realmente Foo).\n",
    "\n",
    "Al utilizar las dos, no solo ponderamos que el modelo tenga una precisión aceptable, sino que también consideramos cuántos casos está encontrando realmente (ya que, el modelo como tal puede no resultar tan útil si lo hace con muy pocos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfadfb89",
   "metadata": {},
   "source": [
    "# Aplicaciones de featuring engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc9cb7",
   "metadata": {},
   "source": [
    "Nuestro dataset posee algunas variables a las que podemos aplicarles \"feature engineering\". Decidimos crear \"division_home\" y \"division_away\" a partir de los datos en las variables \"home_team\" y \"away_team\", de las cuales extraeremos la región a las que pertenecen los equipos en cuestión.\n",
    "\n",
    "Por otra parte, aplicaremos la técnica de \"Quantile Transformation\" para ajustar a una distribución normal aquellas variables de entrada que presentan otro tipo de distribución, eliminando los valores atípicos.\n",
    "\n",
    "Aplicamos técnicas de preprocesado para mejorar la representación de los datos como OneHotEncoder y StandardImputer, y eliminamos los valores nulos utilizando SimpleImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d92c5",
   "metadata": {},
   "source": [
    "## Extraer features a partir de otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regiones\n",
    "east = ['TB','BAL','BOS','TOR','NYY','ATL','MIA','PHI','NYM','WSH']\n",
    "central = ['MIN','CLE','DET','CWS','KC','PIT','MIL','CHC', 'CIN', 'STL']\n",
    "west = ['TEX','LAA','HOU','SEA','OAK','LAD','SD','SF','COL','ARI']\n",
    "\n",
    "def division_h(row):\n",
    "    if east.count(row['home_team']) > 0:\n",
    "        return 'east'\n",
    "    else:\n",
    "        if central.count(row['home_team']) > 0:\n",
    "            return 'central'\n",
    "        else:\n",
    "            return 'west'\n",
    "        \n",
    "def division_a(row):\n",
    "    if east.count(row['away_team']) > 0:\n",
    "        return 'east'\n",
    "    else:\n",
    "        if central.count(row['away_team']) > 0:\n",
    "            return 'central'\n",
    "        else:\n",
    "            return 'west'\n",
    "\n",
    "# Nuevas features que almacenan la región del equipo local y visitante\n",
    "division_home = completa_fe.apply(division_h, axis=1)\n",
    "division_away = completa_fe.apply(division_a, axis=1)\n",
    "completa_fe[\"division_home\"] = division_home\n",
    "completa_fe[\"division_away\"] = division_away\n",
    "\n",
    "# Eliminar features que ya no son necesarias\n",
    "columnas_string=['home_team','away_team']\n",
    "completa_fe = completa_fe.drop(columnas_string,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ed3f4",
   "metadata": {},
   "source": [
    "## Aplicación de QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b4bbc",
   "metadata": {},
   "source": [
    "Las features candidatas para aplicar \"Quantile Transformation\" son \"plate_x\", \"plate_z\", \"pitch_mph\", \"launch_speed\" y \"launch_angle\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar variables, antes y después de aplicar alguna transformación\n",
    "def plots(df, col, t):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    sns.kdeplot(df[col])\n",
    "    plt.title('Antes de aplicar ' + str(t).split('(')[0])\n",
    "\n",
    "    plt.subplot(122)\n",
    "    p1 = t.fit_transform(df[[col]]).flatten()\n",
    "    sns.kdeplot(p1)\n",
    "    plt.title('Después de aplicar ' + str(t).split('(')[0])\n",
    "\n",
    "# Gráficas de variables, antes y después de aplicar Quantile Transformation\n",
    "columns_qt = ['plate_x', 'plate_z', 'pitch_mph', 'launch_speed', 'launch_angle']\n",
    "for col in columns_qt:\n",
    "    plots(completa_fe, col, QuantileTransformer(output_distribution='normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe863f81",
   "metadata": {},
   "source": [
    "Como podemos visualizar en las gráficas, existen variables que ya presentan una distribución normal, mientras que otras presentan otro tipo de distribución. Es por ello, que decidimos aplicar la técnica en aquellas variables que lo requieren, como pitch_mph y launch_speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdd1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "# Creamos columnas con la técnica aplicada\n",
    "completa_fe['pitch_mph_qt'] = qt.fit_transform(completa_fe.pitch_mph.to_frame())\n",
    "completa_fe['launch_speed_qt'] = qt.fit_transform(completa_fe.launch_speed.to_frame())\n",
    "\n",
    "# Eliminar features que ya no son necesarias\n",
    "completa_fe = completa_fe.drop(['pitch_mph', 'launch_speed'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b027b86",
   "metadata": {},
   "source": [
    "## División del dataset con feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset aplicando feature engine en train (60%), test (20%) y validation (20%)\n",
    "train_fe, not_train_fe = train_test_split(completa_fe, test_size=0.4, random_state=42)\n",
    "validation_fe, test_fe = train_test_split(not_train_fe, test_size=0.5, random_state=42)\n",
    "\n",
    "train_fe.shape, validation_fe.shape, test_fe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f22835e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definimos el mapper. Recibe una lista de (columna/s, transformers)\n",
    "mapper_fe = DataFrameMapper([ \n",
    "    (['is_batter_lefty'], None), \n",
    "    (['is_pitcher_lefty'], None), \n",
    "    (['bb_type'], [OneHotEncoder()]), \n",
    "    (['bearing'], [OneHotEncoder()]), \n",
    "    (['pitch_name'], [OneHotEncoder()]), \n",
    "    (['inning'], [StandardScaler()]), \n",
    "    (['outs_when_up'], None), \n",
    "    (['balls'], [StandardScaler()]), \n",
    "    (['strikes'], [StandardScaler()]), \n",
    "    (['plate_x'], [StandardScaler()]), \n",
    "    (['plate_z'], [StandardScaler()]),    \n",
    "    (['launch_angle'], [StandardScaler()]),\n",
    "    (['cover'], [OneHotEncoder()]),\n",
    "    (['lf_dim'], [StandardScaler()]),\n",
    "    (['cf_dim'], [StandardScaler()]),\n",
    "    (['rf_dim'], [StandardScaler()]),\n",
    "    (['lf_w'], [StandardScaler()]),\n",
    "    (['cf_w'], [StandardScaler()]),\n",
    "    (['rf_w'], [StandardScaler()]),\n",
    "    ([\"division_home\"], [OneHotEncoder()]),\n",
    "    ([\"division_away\"], [OneHotEncoder()]),\n",
    "    (['pitch_mph_qt'], [StandardScaler()]),\n",
    "    (['launch_speed_qt'], [StandardScaler()]),\n",
    "])\n",
    "\n",
    "mapper_fe.fit(train_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4bdff",
   "metadata": {},
   "source": [
    "# Modelos a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119178d6",
   "metadata": {},
   "source": [
    "Los modelos que vamos a utilizar van a ser:\n",
    " - K-Nearest Neighbors\n",
    " - Árboles de decisión\n",
    " - Random Forest\n",
    " - Gradient Boost\n",
    " \n",
    "  Por cada modelo, se debe entrenarlo y realizar una exploración de hiper-parámetros mediante una búsqueda en grilla. Evaluar el comportamiento de cada modelo con los hiper-parámetros que mejores resultados ofrecen. En caso de ser posible, aporte conclusiones respecto a dicha comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar modelos (sin aplicar feature engineering)\n",
    "def evaluate_model(model, set_names=('train_nor', 'validation'), title='', show_cm=False):\n",
    "    if title:\n",
    "        display(title)\n",
    "    \n",
    "    final_metrics = {\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],        \n",
    "    }\n",
    "        \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train_nor', 'validation', 'test']\n",
    "        set_data = globals()[set_name]\n",
    "\n",
    "        y = set_data.is_home_run\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d7f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar modelos (aplicando feature engineering)    \n",
    "def evaluate_model_fe(model, set_names=('train_fe', 'validation_fe'), title='', show_cm=False):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = {\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],        \n",
    "    }\n",
    "        \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train_fe', 'validation_fe', 'test_fe']\n",
    "        set_data = globals()[set_name]  # <- hack feo...\n",
    "\n",
    "        y = set_data.is_home_run\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico del árbol\n",
    "def graph_tree(tree, col_names):\n",
    "    graph_data = export_graphviz(\n",
    "        tree, \n",
    "        out_file=None, \n",
    "        feature_names=col_names,  \n",
    "        class_names=['No es home run', 'Home run'],  \n",
    "        filled=True, \n",
    "        rounded=True,  \n",
    "        special_characters=True,\n",
    "    )\n",
    "    graph = graphviz.Source(graph_data)  \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c7dee",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43145f",
   "metadata": {},
   "source": [
    "### Exploración de hiper-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "k_range = list(range(2, 15))\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "clf = GridSearchCV(knn, param_grid, scoring='f1', verbose=1)\n",
    "\n",
    "gs_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "gs_pipe.fit(train_nor, train_nor.is_home_run)\n",
    "clf.best_score_, clf.best_params_\n",
    "\"\"\"\n",
    "\n",
    "# (0.12442273425645493, {'n_neighbors': 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99d421",
   "metadata": {},
   "source": [
    "### Sin feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "k=3\n",
    "knn_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=k)),\n",
    "])\n",
    "inicio = time.time()\n",
    "knn_model.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(knn_model, title='KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b35c3f",
   "metadata": {},
   "source": [
    "### Con feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "k=3\n",
    "knn_model_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=k)),\n",
    "])\n",
    "inicio = time.time()\n",
    "knn_model_fe.fit(train_fe, train_fe.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model_fe(knn_model_fe, title='KNN (aplicando feature engineering)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1f274",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3afe124",
   "metadata": {},
   "source": [
    "A partir de los resultados, podemos determinar que:\n",
    "\n",
    "- El modelo (con la configuración planteada) es capaz de encontrar el 11% de las jugadas que terminaron en home run.\n",
    "- Debido a la diferencia entre Precision y Recall, la configuración usada para este modelo nos devuelve un F1 de aproximadamente 28%.\n",
    "- Con lo anterior, concluimos que el modelo no detecta muy bien las jugadas que son home run, por lo que puede ser necesario que se continúe trabajando con los datos de entrada.\n",
    "- En lo que respecta a la aplicación de feature engineering, los valores de las métricas se ven afectados positivamente al train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9554cfe",
   "metadata": {},
   "source": [
    "## Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10db79",
   "metadata": {},
   "source": [
    "### Exploración de hiper-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033964b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "profundidad = list(range(4, 12))\n",
    "param_grid = dict(max_depth=profundidad)\n",
    "clf = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, scoring='f1', verbose=1)\n",
    "\n",
    "gs_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "gs_pipe.fit(train_nor, train_nor.is_home_run)\n",
    "clf.best_score_, clf.best_params_\n",
    "\"\"\"\n",
    "# Out: (0.5030525830032249, {'max_depth': 5})\n",
    "\n",
    "tree_params = {'max_depth': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574acaf",
   "metadata": {},
   "source": [
    "### Sin feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a109759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_limit = DecisionTreeClassifier(**tree_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "dt_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', tree_model_limit),\n",
    "])\n",
    "inicio = time.time()\n",
    "dt_model.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(dt_model, title='Árbol de decisión')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c0170",
   "metadata": {},
   "source": [
    "### Con feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1076cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_limit_fe = DecisionTreeClassifier(**tree_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "dt_model_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', tree_model_limit_fe),\n",
    "])\n",
    "inicio = time.time()\n",
    "dt_model_fe.fit(train_fe, train_fe.is_home_run)\n",
    "fin = time.time()\n",
    "dt_time_train = fin - inicio\n",
    "print(f\"Demora entrenamiento: {dt_time_train}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model_fe(dt_model_fe, title='Árbol de decisión (aplicando feature engineering)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18802431",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar el árbol de decisión entrenado\n",
    "graph_tree(tree_model_limit, mapper.transformed_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb85b6",
   "metadata": {},
   "source": [
    "A partir de los resultados, podemos determinar que:\n",
    "- El 72% de las ocasiones en las que el modelo predijo un home run, acertó.\n",
    "- El modelo (con la configuración planteada) es capaz de encontrar el 39% de las jugadas que terminaron en home run.\n",
    "- Debido a la diferencia entre Precision y Recall, la configuración usada para este modelo nos devuelve un F1 de aproximadamente 50%.\n",
    "- Con lo anterior, concluimos que el modelo no detecta muy bien las jugadas que son home run, pero cuando lo hace es confiable.\n",
    "- En lo que respecta a la aplicación de feature engineering, los valores de las métricas se ven afectados negativamente.\n",
    "- El árbol no es excesivamente grande para visualizarse, por lo que resulta más simple de entender e interpretar a diferencia de otros modelos. Podemos visualizar que las variables que tienen más impacto en las predicciones son  launch_angle y launch_speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadef57a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76eb90",
   "metadata": {},
   "source": [
    "### Exploración de hiper-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c00d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parameters = {'n_estimators': [100, 200], \n",
    "              'max_depth':[3, 5, 8],\n",
    "              'max_features': [2, 5]}\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, scoring='f1', verbose=1)\n",
    "\n",
    "gs_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "gs_pipe.fit(train_nor, train_nor.is_home_run)\n",
    "clf.best_score_, clf.best_params_\n",
    "\"\"\"\n",
    "# Out: (0.25394347435005404, {'max_depth': 8, 'max_features': 5, 'n_estimators': 200})\n",
    "\n",
    "rf_params = {'max_depth': 8,\n",
    "            'max_features': 5,\n",
    "            'n_estimators': 200\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09452d",
   "metadata": {},
   "source": [
    "### Sin feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a20660",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(**rf_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "rf_model = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', forest_model),\n",
    "])\n",
    "inicio = time.time()\n",
    "rf_model.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(rf_model, title='Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bd65a",
   "metadata": {},
   "source": [
    "### Con feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642bcc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest_model_fe = RandomForestClassifier(**rf_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "rf_model_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', forest_model_fe),\n",
    "])\n",
    "inicio = time.time()\n",
    "rf_model_fe.fit(train_fe, train_fe.is_home_run)\n",
    "fin = time.time()\n",
    "rf_time_train = fin - inicio\n",
    "print(f\"Demora entrenamiento: {rf_time_train}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model_fe(rf_model_fe, title='Random Forest (aplicando feature engineering)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c3f47",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar el árbol de decisión entrenado\n",
    "graph_tree(forest_model.estimators_[0], mapper.transformed_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410098a",
   "metadata": {},
   "source": [
    "A partir de los resultados, podemos determinar que:\n",
    "\n",
    "- El 80% de las ocasiones en las que el modelo predijo un home run, acertó.\n",
    "- El modelo (con la configuración planteada) es capaz de encontrar el 20% de las jugadas que terminaron en home run.\n",
    "- Debido a la diferencia entre Precision y Recall, la configuración usada para este modelo nos devuelve un F1 de aproximadamente 31%.\n",
    "- Con lo anterior, concluimos que el modelo no detecta muy bien las jugadas que son home run, pero cuando lo hace es muy confiable.\n",
    "- En lo que respecta a la aplicación de feature engineering, los valores de las métricas se ven afectados negativamente en F1 y positivamente en Precision.\n",
    "- El árbol es excesivamente grande y complejo, por lo que entenderlo e interpretarlo se dificulta. A pesar de lo anterior, podemos visualizar que las variables que tienen más impacto en las predicciones son  launch_angle, launch_speed y plate_x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7021a2a",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cda9a",
   "metadata": {},
   "source": [
    "### Exploración de hiper-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31474796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e_range = [10, 50, 100, 200]\n",
    "param_grid = dict(n_estimators=e_range)\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), param_grid, scoring= 'f1',refit=True,verbose=1)\n",
    "\n",
    "gs_pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', clf),\n",
    "])\n",
    "\n",
    "gs_pipe.fit(train_nor, train_nor.is_home_run)\n",
    "clf.best_score_, clf.best_params_\n",
    "\"\"\"\n",
    "# Out: (0.5265112649454026, {'n_estimators': 100})\n",
    "\n",
    "gb_params = {'n_estimators':100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57031c30",
   "metadata": {},
   "source": [
    "### Sin feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedfefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(**gb_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "model_gb100 = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', gb_model)\n",
    "])\n",
    "inicio = time.time()\n",
    "model_gb100.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "gb_time_train = fin - inicio\n",
    "print(f\"Demora entrenamiento: {gb_time_train}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(model_gb100, title='Gradient Boosting con n_trees=100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3f6bf",
   "metadata": {},
   "source": [
    "### Con feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_fe = GradientBoostingClassifier(**gb_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "model_gb100_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('classifier', gb_model_fe)\n",
    "])\n",
    "inicio = time.time()\n",
    "model_gb100_fe.fit(train_fe, train_fe.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model_fe(model_gb100_fe, title='Gradient Boosting con n_trees=100 (aplicando feature engineering)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7fd8f3",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f38ae",
   "metadata": {},
   "source": [
    "A partir de los resultados, podemos determinar que:\n",
    "\n",
    "- El 71% de las ocasiones en las que el modelo predijo un home run, acertó.\n",
    "- El modelo (con la configuración planteada) es capaz de encontrar el 41% de las jugadas que terminaron en home run.\n",
    "- Debido a la diferencia entre Precision y Recall, la configuración usada para este modelo nos devuelve un F1 de aproximadamente 52%.\n",
    "- Con lo anterior, concluimos que el modelo no detecta muy bien las jugadas que son home run, pero cuando lo hace es confiable.\n",
    "- En lo que respecta a la aplicación de feature engineering, los valores de las métricas se ven afectados negativamente, por lo que que se podría mejorar en dicho aspecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcffd1fd",
   "metadata": {},
   "source": [
    "# Técnicas de reducción de la dimensionalidad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16863b",
   "metadata": {},
   "source": [
    "El análisis de componentes principales (PCA) es una técnica utilizada para describir un conjunto de datos en términos de nuevas variables no correlacionadas, permite hacer dimensionality reduction. Al algoritmo se le puede indicar en \"n_components\" el número de componentes nuevas que se van a crear o la varianza que se quiere obtener en los datos. En el último caso, el algoritmo seleccionará el número de componentes para conservar el porcentaje de la varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2c659",
   "metadata": {},
   "source": [
    "## Ejemplo demostrativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_pca = DataFrameMapper([ \n",
    "    (['is_batter_lefty'], None), \n",
    "    (['bb_type'], [OneHotEncoder()]),\n",
    "    (['is_pitcher_lefty'], None), \n",
    "    (['bearing'], [OneHotEncoder()]), \n",
    "    (['inning'], [StandardScaler()]), \n",
    "    (['outs_when_up'], None), \n",
    "    (['balls'], [StandardScaler()]), \n",
    "    (['strikes'], [StandardScaler()]), \n",
    "    (['plate_x'], [StandardScaler()]),\n",
    "    (['plate_z'], [StandardScaler()]),   \n",
    "    (['launch_angle'], [StandardScaler()]),\n",
    "    (['launch_speed'], [StandardScaler()]),\n",
    "    (['pitch_mph'], [StandardScaler()]),\n",
    "    (['cover'], [OneHotEncoder()]),\n",
    "    (['lf_dim'], [StandardScaler()]),\n",
    "    (['cf_dim'], [StandardScaler()]),\n",
    "    (['rf_dim'], [StandardScaler()]),\n",
    "    (['lf_w'], [StandardScaler()]),\n",
    "    (['cf_w'], [StandardScaler()]),\n",
    "    (['rf_w'], None),\n",
    "])\n",
    "\n",
    "mapper_pca.fit(train)\n",
    "\n",
    "pipe_pca1 = Pipeline([\n",
    "    ('mapper', mapper_pca),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "])\n",
    "\n",
    "# preparar los datos\n",
    "pipe_pca1.fit(train)\n",
    "train_pca=pipe_pca1.transform(train)\n",
    "train_pca= pd.DataFrame(train_pca, columns=mapper_pca.transformed_names_)\n",
    "\n",
    "#aplicar la técnica de redución de dimensionalidades\n",
    "pca_pipe = PCA(n_components=2, svd_solver=\"auto\", random_state=42)\n",
    "pca_pipe.fit(train_pca)\n",
    "results = pca_pipe.fit_transform(train_pca)\n",
    "\n",
    "#armar el dataframe con los datos obtenidos de la aplicación de PCA\n",
    "results_red=pd.DataFrame({'PCA1':results[:,0], 'PCA2':results[:,1], 'clase':train.is_home_run})\n",
    "\n",
    "sns.barplot(x=[\"PCA1\",\"PCA2\"], y=pca_pipe.explained_variance_ratio_)\n",
    "print(pca_pipe.explained_variance_ratio_)\n",
    "print(pca_pipe.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d7461",
   "metadata": {},
   "source": [
    "En lo anterior, podemos ver que aplicando dicha técnica y seleccionando la formación de dos componenetes, obtenemos que los mismos van a representar el 72% de la información total del dataset. Para perder menos infomración se podría aumentar el número de componentes. Como consecuencia, con las componentes calculadas en el ejemplo, se podrían utilizar modelos que no funcionan bien con muchas dimensiones, se ahorraría tiempo y recurso de hardware algoritmos de machine learning que usen esta data y se podría visualizar más facilmente la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989e16c",
   "metadata": {},
   "source": [
    "## Árboles de decisión con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_limit_pca = DecisionTreeClassifier(**tree_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "dt_model_pca = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', tree_model_limit_pca),\n",
    "])\n",
    "start = time.time()\n",
    "dt_model_pca.fit(train_nor, train_nor.is_home_run)\n",
    "stop = time.time()\n",
    "print(f\"Demora entrenamiento: {stop - start}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(dt_model_pca, title='Árbol de decisión (aplicando PCA)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9ae36",
   "metadata": {},
   "source": [
    "## Random Forest con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model_pca = RandomForestClassifier(**rf_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "rf_model_pca = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', forest_model_pca),\n",
    "])\n",
    "inicio = time.time()\n",
    "rf_model_pca.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(rf_model_pca, title='Random Forest (aplicando PCA)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01949177",
   "metadata": {},
   "source": [
    "## Gradient Boost con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_pca = GradientBoostingClassifier(**gb_params, random_state=42)\n",
    "\n",
    "# Entrenamiento\n",
    "model_gb100_pca = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer(random_state=42)),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('classifier', gb_model_pca),\n",
    "])\n",
    "inicio = time.time()\n",
    "model_gb100_pca.fit(train_nor, train_nor.is_home_run)\n",
    "fin = time.time()\n",
    "print(f\"Demora entrenamiento: {fin - inicio}s\")\n",
    "\n",
    "# Evaluación\n",
    "evaluate_model(model_gb100_pca, title='Gradient Boosting con n_trees=100 (aplicando PCA)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bfd12",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce6023",
   "metadata": {},
   "source": [
    "PCA permite resumir la información de un gran número de features en un número limitado de componentes, pero dichos componentes no suelen ser intuitivos. Comparandolo con los modelos anteriores que no aplican PCA, concluimos que en nuestro caso no mejora el rendimiento de la predicción, la razón seguramente se deba a la pérdida de información que implica el reducir la dimensión del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb596ea7",
   "metadata": {},
   "source": [
    "# Técnicas para evitar overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece4e3d",
   "metadata": {},
   "source": [
    "En relación a las técnicas para evitar overfitting que aplicamos a lo largo del problema podemos mencionar que llevamos a cabo las siguientes acciones:\n",
    "- Dividimos los datasets (con y sin feature engineering) en train, test y validation. Esto nos permite obtener una valoración de aciertos/fallos del modelo, y compararlos entre subconjuntos para detectar fácilmente overfitting/underfitting.\n",
    "- Modificamos los hiperparámetros en los modelos utilizados para que no sobreentrene. Por ejemplo, al establecer una profundidad de árbol y, de esa forma, evitar que el árbol de decisión se ajuste perfectamente al set de entrenamiento.\n",
    "- Una mayor cantidad de datos permite que el modelo pueda generalizar mejor, teniendo en cuenta más tipos de datos, en nuestro caso podríamos utilizar datasets de otras temporadas.\n",
    "- Eliminamos datos que podían llegar a provocar sobreentrenamiento tales como ids y nombres propios de personas, equipos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037408eb",
   "metadata": {},
   "source": [
    "# Selección del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(knn_model, title='KNN', set_names=('train_nor', 'validation','test'))\n",
    "print(f\"Demora entrenamiento: {dt_time_train}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e245f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_model, title='Árboles de decisión', set_names=('train_nor', 'validation','test'))\n",
    "print(f\"Demora entrenamiento: {dt_time_train}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_model, title='Random Forest', set_names=('train_nor', 'validation','test'))\n",
    "print(f\"Demora entrenamiento: {rf_time_train}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b915694",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_gb100, title='Gradient Boosting con n_trees=100', set_names=('train_nor', 'validation','test'))\n",
    "print(f\"Demora entrenamiento: {gb_time_train}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21420b7",
   "metadata": {},
   "source": [
    "Los modelos candidatos son árboles de decisión y Gradient Boosting, ya que presentan los valores más altos en F1 (que considera tanto la Precision como el Recall) utilizando el conjunto de datos \"validation\". Además, los tiempos de entrenamiento de ambos son similares y la diferencia entre el rendimiento del conjunto \"train\" y \"validation\" no es tan amplia en ninguno de los dos casos. Al final, optamos por el modelo de árboles de decisión debido a que los mismos pueden resultar más simples e intuitivos para que el cliente pueda interpretarlos.\n",
    "\n",
    "La métrica final que será informada la conseguimos a partir del conjunto de datos \"test\", para obtener un valor lo más realista posible. De esta forma, al momento de informar al cliente acerca del rendimiento del modelo, se le comunica que posee una precisión del 68% y que es capaz de identificar el 48% de los casos en que una jugada termina en home run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8f3a6",
   "metadata": {},
   "source": [
    "# Diagramas de dispersión con aciertos y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar modelos (sin aplicar feature engineering)\n",
    "def evaluate_model(model, set_names=('train_nor', 'validation'), title='', show_cm=False):\n",
    "    if title:\n",
    "        display(title)\n",
    "    \n",
    "    final_metrics = {\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],        \n",
    "    }\n",
    "        \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train_nor', 'validation', 'test']\n",
    "        set_data = globals()[set_name]\n",
    "\n",
    "        y = set_data.is_home_run\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        final_metrics['Recall'].append(metrics.recall_score(y, y_pred))\n",
    "        final_metrics['F1'].append(metrics.f1_score(y, y_pred))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))\n",
    "    return y_pred\n",
    "\n",
    "y_pred=evaluate_model(dt_model, title='Árboles de decisión', set_names=('train_nor', 'validation','test'))\n",
    "\n",
    "#Función para obtener valores correctos y errores\n",
    "def comparar_resultados(row):\n",
    "    if (row['is_home_run']) == 0 and (row['is_home_run'])!=(row['resultados_reales']):\n",
    "        return 2\n",
    "    else:\n",
    "        if (row['is_home_run']) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            if (row['is_home_run']) == 1 and (row['is_home_run'])!=(row['resultados_reales']):\n",
    "                return 3\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "validation[\"resultados_reales\"]=y_pred\n",
    "resultados_finales = validation.apply(comparar_resultados, axis=1)\n",
    "validation[\"resultados_finales\"]=resultados_finales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a2e55",
   "metadata": {},
   "source": [
    "### Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8e1b1",
   "metadata": {},
   "source": [
    " - 0: Era False y dijo False\n",
    " - 1: Era True y dijo True\n",
    " - 2: Era False y dijo True\n",
    " - 3: Era True y dijo False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6337a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=validation.launch_angle, y=validation.launch_speed, hue=validation.resultados_finales, data=validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987225ff",
   "metadata": {},
   "source": [
    "En el gráfico podemos observar la relación entre los aciertos y los errores en la predicción de la variable de salida con relación a las variables launch_speed y launch_angle. Si bien no se ve tan claramente porque hay una gran cantidad de datos superpuestos, podemos decir que el algoritmo no pudo encontrar la relación entre los rangos de ambas variables, debido a que en la parte donde más positivos había no obtuvo buenas predicciones. Esto podría deberse a que priorizaba decir \"False\" debido al desbalance de los datos. Esto se podría solucionar asignando pesos a las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=validation.bb_type, y=validation.pitch_mph, hue=validation.resultados_finales, data=validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d787e",
   "metadata": {},
   "source": [
    "En el gráfico podemos observar la relación entre los aciertos y los errores en la predicción de la variable de salida con relación a las variables pitch_mph y bb_type. Como en el caso anterior, no se ven tan claramente todos los puntos porque hay una gran cantidad de datos superpuestos, pero podemos decir que el algoritmo no pudo encontrar tanto la relación entre las categorías de bb_type (tipo de bola bateada) que a una determinada pitch_mph (velocidad de bola lanzada) puede terminar en home run o no. Esto se hace visible por la aparición de un importante números de puntos \"Era True y dijo False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c52b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
